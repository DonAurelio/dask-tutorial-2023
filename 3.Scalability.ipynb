{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1aace1b-44a0-4f40-acd1-9bf395bc4ce9",
   "metadata": {},
   "source": [
    "<a href=\"https://www.dask.org/\" target=\"_blank\">\n",
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "</a>\n",
    "\n",
    "# Scalability\n",
    "\n",
    "In this notebook, we will explain how Dask achieves scalability from multi-core local machines to large distributed clusters in the cloud for conducting large scale data analytics.\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "Dask employs the **client-server model** to map computations to multiple cores in a single machine or distributed clusters. \n",
    "\n",
    "* In the client-side, a Python/Notebook application can send tasks (computations) to a **Dask Cluster**.\n",
    "* A Dask Cluster is composed of a **scheduler** and the **workers**.\n",
    "* The scheduler receives tasks (computations) and decide which worker will perform every task.\n",
    "* The workers perform computations and store/share results with other workers.\n",
    "\n",
    "<center>\n",
    "<img src=\"img/dask-cluster.png\" width=\"80%\"/>\n",
    "</center>\n",
    "<center>\n",
    "<a href=\"https://tutorial.dask.org/00_overview.html\" target=\"_blank\" width=\"30%\"> Reference: Dask Tutorial Documentation </a>\n",
    "</center>\n",
    "\n",
    "**Content**\n",
    "\n",
    "1. Cluster in a Local Machine.\n",
    "2. Cluster in a High Performance Computing System.\n",
    "3. Cluster in a Cloud Computing System."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c12917-9c62-4aa9-a5d3-7e2fc7f4dd9e",
   "metadata": {},
   "source": [
    "## 1. Cluster in a Local Machine\n",
    "\n",
    "The local cluster is the best option for researchers who are **just learning Dask** or **just starting a large-scale data analysis**. This configuration allows the realization of preliminary tests to later deploy the solution in large Supercomputers or Cloud Computing infrastructure. \n",
    "\n",
    "You can define a local cluster in two ways [2].\n",
    "\n",
    "* Implicitly, Dask crteates a default local cluster for you.\n",
    "* Explicitly, You define the local cluster by yourself using the Dask library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa4a7d-91ec-4b2d-9334-a962fe664dbc",
   "metadata": {},
   "source": [
    "### 1.1. Implicit cluster definition\n",
    "\n",
    "In the implicit mode, the user doesn't have to define the cluster. Once the user defines a computation and uses the method `compute`, a default cluster is created for her. The default configuration uses all computer's available cores. More information can be found in [2]. Let's take a look on this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a07c3-3324-4596-b6d2-93012093c575",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f682f-1c81-4ad4-94ba-c0977e8c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef68e1-8e5b-40e4-874f-22c691bd5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.random.random((10000,10000), chunks=(1000,1000))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d1979-78ea-46ce-a1eb-3b84633951a5",
   "metadata": {},
   "source": [
    "__2. Visualize the computations to be performed per array chunk.__\n",
    "\n",
    "_Hint: This computations will be performed in the cores available in your computer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6d5d7-0abe-4279-a3ae-9fb0ae0c8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.visualize() # not working yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665feb6a-008e-4638-a4eb-3cdc1343471f",
   "metadata": {},
   "source": [
    "__3. Compute the result__\n",
    "\n",
    "_Hint: Dask submit all the computations to the scheduler, then, the scheduler will be in charge of distributing the computations among the available computing cores._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fb306-1c85-45e1-929b-df0c359de719",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.compute() # This uses Dask default local cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6b1ae-cbe1-4559-ae65-213d83fe8965",
   "metadata": {},
   "source": [
    "__4. Get `compute` method documentation for available parameters.__\n",
    "\n",
    "_Hint: Advanced users can decide if they want to execute their computations using `threads` or `processes` by setting the scheduler parameter, `.compute(scheduler=)`. In addition they can decide if they want their computations to run sequentially by setting the scheduler option to `synchronous`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d9999-6a42-40e5-9117-00842ce99c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(x.compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f4a3a-62f7-424a-a711-f99049f31b73",
   "metadata": {},
   "source": [
    "### 1.2. Explicit cluster definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fddd2-9bf0-4ef7-99bc-8047a1b187fe",
   "metadata": {},
   "source": [
    "Advanced users prefer to define the cluster by themsleves, i.e., explicitly, this give to them more flexibility for the configuration of the cluster. For example, they can define how many **workers** they want to use and how many `cores` and `memory` they want each worker to have. Finally, when you define the cluster by yourself, you will be able to access the **Dask Dashborad**.\n",
    "\n",
    "In the explicit mode, you can define a cluster in one of two ways:\n",
    "* By defining the client\n",
    "* By defining the cluster and the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d974899-bc31-4d0d-b04f-70612832cd71",
   "metadata": {},
   "source": [
    "#### 1.2.1. By defining the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd078d-5f32-4ef0-ae1e-b45f25e5f27f",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598be83-9203-4e51-af1c-17566676af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0f2b4-1f84-4c75-b5ff-144f25918aad",
   "metadata": {},
   "source": [
    "__2. Create a cluster by defining the client__\n",
    "\n",
    "_Hint: The creation of the client, implies the creation of a cluster._\n",
    "\n",
    "_Note: **Be carefull** you should not execute the cell bellow multiple times, that will create a lot of clusters._\n",
    "\n",
    "_Activities:_ \n",
    "\n",
    "1. Run the cell bellow\n",
    "2. Use the option `Lauch dashborad in JupyterLab`, this will display the Dask Dashboard.\n",
    "3. In the Dashboard you will need to change the ip addres from `127.0.0.1` to `192.5.87.217`\n",
    "4. The Daskboard has a plently of options to evaluate the performance of our cluster when performing a computation. Take a look on some of the options, for instance `cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85732f32-972b-4ea6-985b-014252eaf356",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aed329-0520-4eb5-8b1e-9c40fea3edf1",
   "metadata": {},
   "source": [
    "__3. Perform some computation__\n",
    "\n",
    "_Hint: Use the Dashboard to see what is happenning while your computation is taking place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b793e-9b92-41bf-9c99-981648db2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random timeseries of data\n",
    "df = dask.datasets.timeseries(\"2000\", \"2005\", partition_freq=\"2w\").persist()\n",
    "\n",
    "# perform a groupby with an aggregation\n",
    "df.groupby(\"name\").aggregate({\"x\": \"sum\", \"y\": \"max\"}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b45504-2c7a-476b-a44c-d8bf5b51956f",
   "metadata": {},
   "source": [
    "__4. Showdown the cluster__\n",
    "\n",
    "_Hint: This is **MANDATORY**, one you finish using a cluster you must turn it of, since it will release the computing resources your cluster was using_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb14184-6c6d-4a7d-957f-cf1f166cc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the cluster \n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527cc2f-b97d-4f00-806c-4286dcca5f2b",
   "metadata": {},
   "source": [
    "__5. Close the connection between the client and the cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec1581-8b6a-40d3-a2a6-2a513ac325a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17868f29-206f-4f59-aa73-48cd9fc76402",
   "metadata": {},
   "source": [
    "#### 1.2.2. By defining the cluster and the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a19a63-d233-42dc-963e-06bfab3ef850",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4aba66-c424-4639-afee-84cb551e4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bfa40d-ca14-4c2e-9e9d-e0b068488ef9",
   "metadata": {},
   "source": [
    "__2. Create a Dask cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ce4c5-c5d1-4828-ae25-53ed38e218b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()  # Launches a scheduler and workers locally\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdaf9-5459-4e37-8af1-925d2b8a1b72",
   "metadata": {},
   "source": [
    "__3. Create a Dask Client and connect the client to the Dask cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef94ec-41c0-413d-8137-38c8d765cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)  # Connect to distributed cluster and override default\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa427a3-4913-4915-a703-4ba5f8a75216",
   "metadata": {},
   "source": [
    "__3. Perform some computation__\n",
    "\n",
    "_Hint: Use the Dashboard to see what is happenning while your computation is taking place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2bd20-6385-4775-b213-8e4678d46a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random timeseries of data\n",
    "df = dask.datasets.timeseries(\"2000\", \"2005\", partition_freq=\"2w\").persist()\n",
    "\n",
    "# perform a groupby with an aggregation\n",
    "df.groupby(\"name\").aggregate({\"x\": \"sum\", \"y\": \"max\"}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21c210-288e-4497-a88b-585026aaa504",
   "metadata": {},
   "source": [
    "__3. Showdown the cluster__\n",
    "\n",
    "_Hint: This is **MANDATORY**, one you finish using a cluster you must turn it of, since it will release the computing resources your cluster was using_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d1a43-3c4a-4da3-af71-c6b6ab3c2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688da097-c75b-4741-afe2-57041e008788",
   "metadata": {},
   "source": [
    "__4. Close the connection between the client and the cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03052df-6ff4-42f3-ac59-8e4d5233cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ec3d35a-ff94-4225-8874-353d4d67e7b2",
   "metadata": {},
   "source": [
    "## 2. Cluster in a High Performance Computing System\n",
    "\n",
    "The High Performance Computing (HPC) system for researchers with a clear research objective and understanding on how to use Dask to scale their experiments beyond the capabilities of a single computer. Depending on how Dask was configured in the HPC, it willbring significant advantages in communication-intensive computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f55345-7eeb-4477-bee7-e7f3345f4d5f",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a9e6-7ec9-45b7-a2c3-4aa2c5b31db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2ff6d-c0bb-4404-bbdc-6ebc164004a3",
   "metadata": {},
   "source": [
    "__2. Create a Dask cluster__\n",
    "\n",
    "_Hint: Here you will define how namy `cores` and `memory` will have every Dask worker._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b7133-348e-4557-8b9f-a6180e75b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    cores=1,\n",
    "    memory=\"2 GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65464e0-2ca8-4b30-adda-30d2825a40e8",
   "metadata": {},
   "source": [
    "__3. Deploy workers for your Dask cluster__\n",
    "\n",
    "_Hint: each worker will be a slurm job._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7f192-790b-4761-8a4f-fd5b234b9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dff629-05d1-4464-9b2d-1841238c8b0a",
   "metadata": {},
   "source": [
    "__5. Check if the Dask worker were deployed in the High Performance Computing System.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dc2cb-e2cd-4da0-bf4f-3595d9d7671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u `whoami`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38173f9-b544-4ad2-ab1c-a22c0d0963e4",
   "metadata": {},
   "source": [
    "__4. Adjust the number of workers according to the workload__\n",
    "\n",
    "_Hint: This also works with adaptive clusters. This automatically launches and kill workers based on load [7]._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2896ce4-d27b-42ae-92ef-b69643927a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum_jobs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d7223-4f1d-49e6-ace1-5272eb63c31b",
   "metadata": {},
   "source": [
    "__6. Create a Dask Client and connect the client to the Dask cluster in the High Performance Computing System__\n",
    "\n",
    "_Activities:_ \n",
    "\n",
    "1. Run the cell bellow\n",
    "2. Use the option `Lauch dashborad in JupyterLab`, this will display the Dask Dashboard.\n",
    "3. The Daskboard has a plently of options to evaluate the performance of our cluster when performing a computation. Take a look on some of the options, for instance `cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa8ca6-08d3-480a-8b9a-c6c94c3b6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)  # Connect to distributed cluster and override default\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223cd5f-bfcf-406f-95e6-7fdccd275269",
   "metadata": {},
   "source": [
    "__7. Perform some computation__\n",
    "\n",
    "_Hint: Use the Dashboard to see what is happenning while your computation is taking place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813933e-e96a-48e5-8452-24568002c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random timeseries of data\n",
    "df = dask.datasets.timeseries(\"2000\", \"2005\", partition_freq=\"2w\").persist()\n",
    "\n",
    "# perform a groupby with an aggregation\n",
    "df.groupby(\"name\").aggregate({\"x\": \"sum\", \"y\": \"max\"}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25122b6-0feb-4822-ab03-1122ceab935c",
   "metadata": {},
   "source": [
    "__8. Showdown the cluster__\n",
    "\n",
    "_Hint: This is **MANDATORY**, one you finish using a cluster you must turn it of, since it will release the computing resources your cluster was using_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b86df-4de0-425b-b4fc-f2c0966d185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4dfd4-5143-42e6-92d7-0e99590a02bb",
   "metadata": {},
   "source": [
    "__9. Close the connection between the client and the cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef29bf-c678-4c8b-b3c5-c294f1fc147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f30e6-f3b2-43a2-8317-9dbd1b41ae28",
   "metadata": {},
   "source": [
    "<a href=\"https://www.dask.org/\" target=\"_blank\">\n",
    "<img src=\"img/coiled.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "</a>\n",
    "\n",
    "\n",
    "## 3. Cluster in a Cloud Computing System\n",
    "\n",
    "Easy, secure and efficient computing\n",
    "with Dask and Coiled. Coiled manages your cloud resources.\n",
    "\n",
    "<center>\n",
    "<img src=\"img/coiled-cloud.png\" width=\"60%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bc451-2025-4e1f-951d-e4da7727f787",
   "metadata": {},
   "source": [
    "__1. Authenticate in the Coiled cloud__\n",
    "\n",
    "Hint: For authentication you will need a token, this toke will be provided by the tutor. Then replace `[ASK_YOUR_TUTOR_FOT_THE_TOKEN]` by the token. \n",
    "\n",
    "1. Open a terminal.\n",
    "2. Update the token in the command bellow and execute it in the terminal.\n",
    "\n",
    "```bash\n",
    "coiled login --token [ASK_YOUR_TUTOR_FOT_THE_TOKEN] --account dask-tutorials\n",
    "```\n",
    "\n",
    "3. Use the following command to deploy the tutorial in Coiled\n",
    "\n",
    "```bash\n",
    "coiled notebook start --software dask-tutorial-hpc-2023\n",
    "```\n",
    "4. Once you have finished, use Control + c to close the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52740f34-3b4f-4804-9cf4-cd8275e7d022",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51040728-2660-4b5a-a6aa-2bed961af907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import coiled\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f875bbf-cf88-4895-a214-0e0666378e12",
   "metadata": {},
   "source": [
    "__2. Create a Dask cluster using the Coiled API__\n",
    "\n",
    "_Hint: Change `...` by your user name. For example `ss0`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a8c58-4a9c-439e-a30b-5186a44fb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(name=...,n_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a5a1d-8ee5-4417-9ade-35e5b60877cb",
   "metadata": {},
   "source": [
    "__3. Create a Dask Client and connect the client to the Dask cluster in Coiled__\n",
    "\n",
    "_Activities:_ \n",
    "\n",
    "1. Run the cell bellow\n",
    "2. Use the option `Lauch dashborad in JupyterLab`, this will display the Dask Dashboard.\n",
    "3. The Daskboard has a plently of options to evaluate the performance of our cluster when performing a computation. Take a look on some of the options, for instance `cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb64f1-0ba4-41c0-bb96-32eaa72f7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b319b6-2469-43c8-8601-e5b5015cc334",
   "metadata": {},
   "source": [
    "__4. Run some computation__\n",
    "\n",
    "_Hint: Use the Dashboard to see what is happenning while your computation is taking place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7aa7b1-864f-47c1-bb30-76b297f6c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random timeseries of data\n",
    "df = dask.datasets.timeseries(\"2000\", \"2005\", partition_freq=\"2w\").persist()\n",
    "\n",
    "# perform a groupby with an aggregation\n",
    "df.groupby(\"name\").aggregate({\"x\": \"sum\", \"y\": \"max\"}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e6027-7270-4762-9653-0a0b941d98e6",
   "metadata": {},
   "source": [
    "__6. Showdown the cluster__\n",
    "\n",
    "_Hint: This is **MANDATORY**, one you finish using a cluster you must turn it of, since it will release the computing resources your cluster was using_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cb3ec-f615-4b77-94a3-469bf1485269",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4e09b-2e47-4bf6-b795-0a69c77c80c2",
   "metadata": {},
   "source": [
    "__7. Close the connection between the client and the cluster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208902a-3545-4f01-b5ec-033258c343e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b617f9-78b6-46bb-a14b-0b722979cc1d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Deploy Dask Clusters - https://docs.dask.org/en/stable/deploying.html\n",
    "2. Single-Machine Scheduler - https://www.devdoc.net/python/dask-2.23.0-doc/setup/single-machine.html\n",
    "3. Getting Started with Dask: A Dask Setup Guide - https://www.youtube.com/watch?v=TQM9zIBzNBo&t=82s\n",
    "4. Scheduler Overview - https://docs.dask.org/en/stable/scheduler-overview.html\n",
    "5. JupyterLab Extension: How to Integrate Dask Dashboards & JupyterLab in 5 Minutes - https://www.youtube.com/watch?v=EX_voquHdk0&t=293s\n",
    "6. Dask on HPC Introduction - https://www.youtube.com/watch?v=FXsgmwpRExM&t=9s\n",
    "7. dask_jobqueue.SLURMCluster - https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html\n",
    "8. Configure Dask-Jobqueue - https://jobqueue.dask.org/en/latest/configuration-setup.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
